{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90066df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "from numpy.core.multiarray import dtype\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "from pylab import rcParams\n",
    "\n",
    "matplotlib.use('agg')\n",
    "np.random.seed(42)\n",
    "# tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466ec93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length:  581888\n"
     ]
    }
   ],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 12, 5\n",
    "\n",
    "\n",
    "#Loading the data\n",
    "path = '1661-0.txt'\n",
    "text = open(path, \"r\", encoding='utf-8').read().lower()\n",
    "print ('Corpus length: ',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b27adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars:  73\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "#Finding all the unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print (\"unique chars: \",len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126600c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples:  193950\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 39\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(text[i:i+SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i+SEQUENCE_LENGTH])\n",
    "print ('num training examples: ',len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a8c165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7912\\1719515540.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7912\\1719515540.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "#Generating features and labels.\n",
    "\n",
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1017132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82e32b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1440/1440 [==============================] - 186s 123ms/step - loss: 2.5938 - accuracy: 0.2687 - val_loss: 2.5594 - val_accuracy: 0.2891\n",
      "Epoch 2/2\n",
      "1440/1440 [==============================] - 180s 125ms/step - loss: 2.2404 - accuracy: 0.3484 - val_loss: 2.4678 - val_accuracy: 0.3155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Downloads\\anaconda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "optimizer = RMSprop(lr= 0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history\n",
    "\n",
    "\n",
    "#Saving\n",
    "model.save('keras_model'+str(SEQUENCE_LENGTH)+'.h5')\n",
    "pickle.dump(history, open('history'+str(SEQUENCE_LENGTH)+'.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892281eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading back the saved weights and history\n",
    "\n",
    "model = load_model('keras_model'+str(SEQUENCE_LENGTH)+'.h5')\n",
    "history = pickle.load(open('history'+str(SEQUENCE_LENGTH)+'.p', 'rb'))\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc= 'upper left')\n",
    "\n",
    "plt.savefig(\"01.Accuracy.png\")\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc= 'upper left')\n",
    "\n",
    "plt.savefig(\"02.Loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ad276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1\n",
    "    return x\n",
    "#The sequences must be 40 chars long and the tensor is of the shape (1, 40, 57)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627b5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sample function\n",
    "def sample(preds, top_n = 3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92b2befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction function\n",
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generalised = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "\n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5eabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n = 3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n",
    "\n",
    "quotes = [\n",
    "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
    "    \"That which does not kill us makes us stronger.\",\n",
    "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
    "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
    "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c97c1ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not a lack of love, but a lack of\n",
      "[' the ', '\\nthe ', 'e ', 're ', 'oun ']\n",
      "\n",
      "that which does not kill us makes us st\n",
      "['our ', 'ere ', 'ate ', 'ing ', 'he ']\n",
      "\n",
      "i'm not upset that you lied to me, i'm \n",
      "['and ', 'the ', 'in ', 'of ', 'southe ']\n",
      "\n",
      "and those who were seen dancing were th\n",
      "['e ', 'at ', 'it ', 'o ', ' the ']\n",
      "\n",
      "it is hard enough to remember my opinio\n",
      "['n ', ' hat ', 't ', 'f ', 's ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:SEQUENCE_LENGTH].lower()\n",
    "    print (seq)\n",
    "    print (predict_completions(seq, 5))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fc650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
